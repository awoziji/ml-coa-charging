{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JolileErHCaH"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQu1f-QmGexE"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from config import REGION, BUCKET, PROJECT, DELIM, RAW_DATA_COLS, RENAMED_COLS, LABEL_COL, STRING_COLS, FLOAT_COLS\n",
    "\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8e1gHCT4GlCH"
   },
   "source": [
    "# Cloud Setup\n",
    "This section is only required if running on cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJnHrsFHGlVQ"
   },
   "outputs": [],
   "source": [
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otbgjhTeGn-f"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2O9fiCiOGrxu"
   },
   "source": [
    "# Data Profiling\n",
    "Data profiling is done to better understand the data, and to see if there are any invalid data (e.g. out of bounds data, unexpected data types). No data preprocessing should be done here; it should be done in tf.transform so as to have a consistent data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob('data/raw/raw_data_invoices_2015-2017.csv')\n",
    "# df = pd.concat([pd.read_csv(\n",
    "#     f, usecols=RAW_DATA_COLS, quoting=csv.QUOTE_ALL, sep=',', encoding='utf-16', dtype='str'\n",
    "#     ) for f in files], ignore_index=True)\n",
    "# df.columns = RENAMED_COLS\n",
    "# acc_code_freq = df.groupby('acc_code').size().rename('count').reset_index()\n",
    "# acc_codes_to_include = list(acc_code_freq[acc_code_freq['count'] >= 30].acc_code)\n",
    "# df = df[df['acc_code'].isin(acc_codes_to_include)]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    df = pd.read_csv(\n",
    "        filename,\n",
    "        sep='\\t',\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "        usecols=RAW_DATA_COLS\n",
    "    )\n",
    "    df.columns = RENAMED_COLS\n",
    "    df['amount'] = df['amount'] \\\n",
    "        .str.replace(',', '') \\\n",
    "        .apply(lambda num: '-' + num if num.find('(') != -1 else num) \\\n",
    "        .str.replace('\\(|\\)', '') \\\n",
    "        .astype('float')\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = read_data('data/raw/raw_data_invoices_2015-2017_20181110.txt')\n",
    "eval_df = read_data('data/raw/raw_data_invoices_2018_20181110.txt')\n",
    "\n",
    "df = pd.concat([train_df, eval_df])\n",
    "acc_code_freq = df.groupby('acc_code').size().rename('count').reset_index()\n",
    "acc_codes_to_include = list(acc_code_freq[acc_code_freq['count'] >= 30].acc_code)\n",
    "train_df = train_df[train_df['acc_code'].isin(acc_codes_to_include)]\n",
    "eval_df = eval_df[eval_df['acc_code'].isin(acc_codes_to_include)]\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-y2ucs2jHPrX"
   },
   "outputs": [],
   "source": [
    "ProfileReport(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProfileReport(train_df).to_file('img/train.html')\n",
    "ProfileReport(eval_df).to_file('img/eval.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmEgecH0HRgZ"
   },
   "source": [
    "# Split Data\n",
    "Example uses 80-10-10 split for train, eval and test - change if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM_SEED = 42\n",
    "# x = df.drop(LABEL_COL, axis=1)\n",
    "# y = df[[LABEL_COL]]\n",
    "# x_train, x_eval, y_train, y_eval = train_test_split(x, y, random_state=RANDOM_SEED, train_size=0.8, stratify=y)\n",
    "# x_eval, x_test, y_eval, y_test = train_test_split(x_eval, y_eval, random_state=RANDOM_SEED, train_size=0.5, stratify=y_eval)\n",
    "# train_df = pd.concat([x_train, y_train], axis=1)\n",
    "# eval_df = pd.concat([x_eval, y_eval], axis=1)\n",
    "# test_df = pd.concat([x_test, y_test], axis=1)\n",
    "\n",
    "# # reorder columns\n",
    "# train_df = train_df[RENAMED_COLS]\n",
    "# eval_df = eval_df[RENAMED_COLS]\n",
    "# test_df = test_df[RENAMED_COLS]\n",
    "\n",
    "# len(train_df), len(eval_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_dc6vYGGv0H"
   },
   "outputs": [],
   "source": [
    "test_df = eval_df[eval_df.business_unit.isin(['CCY', 'MND'])]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YlsukCL7I9sg"
   },
   "outputs": [],
   "source": [
    "def export_datasets(on_cloud=False):\n",
    "    if on_cloud:\n",
    "        data_dir = 'gs://{bucket}/{project}/data/split'.format(bucket=BUCKET, project=PROJECT)\n",
    "    else:\n",
    "        data_dir = 'data/split'\n",
    "    \n",
    "    if not on_cloud:\n",
    "        if not os.path.exists('data'):\n",
    "            os.mkdir('data')\n",
    "        if not os.path.exists('data/split'):\n",
    "            os.mkdir('data/split')\n",
    "        \n",
    "#     def export_df(df, filename):\n",
    "#         full_path = os.path.join(data_dir, filename)\n",
    "#         csv_str = '\\n'.join(DELIM.join(str(r) for r in rec) for rec in df.to_records(index=False))\n",
    "#         with open(full_path, 'w') as f:\n",
    "#             f.write(csv_str)\n",
    "    \n",
    "#     export_df(train_df, 'train.csv')\n",
    "#     export_df(eval_df, 'eval.csv')\n",
    "#     export_df(test_df, 'test.csv')\n",
    "\n",
    "    def export_df(df, filename):\n",
    "        full_path = os.path.join(data_dir, filename)\n",
    "        df.to_csv(full_path, sep='\\t', quoting=csv.QUOTE_NONE, index=False)\n",
    "        \n",
    "    export_df(train_df, 'train.tsv')\n",
    "    export_df(eval_df, 'eval.tsv')\n",
    "    export_df(test_df, 'test.tsv')\n",
    "    \n",
    "    if not os.path.exists('data/misc'):\n",
    "        os.mkdir('data/misc')\n",
    "    with open('./data/misc/labels.txt', 'w') as f:\n",
    "        label_vocab = DELIM.join(list(df[LABEL_COL].astype('str').unique()))\n",
    "        f.write(label_vocab)\n",
    "  \n",
    "    return\n",
    "  \n",
    "export_datasets(on_cloud=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "01-data_preproc.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
